<!--
{
  "title": "Diary (2017-09-01 -- 2017-09-20)",
  "date": "2017-09-02T10:20:10+09:00",
  "special": true
}
-->

# 2017-09-01

- lxqt, openbox
    - it didn't feel good. lxqt-panel died for some search query. input customization didn't work (eg scroll opposite).
- dbus service activation
    - https://www.freedesktop.org/wiki/IntroductionToDBus/
    - it seems ladishd starts this way
- policy kit
    - https://www.freedesktop.org/software/polkit/docs/latest/
    - still confused the difference from pam
- build gnome shell with jhbuild
    - see examples in gtk+3 repo, I don't feel good about whole macro things.
      but, gnome shell is too good to use so I have to read the source.
- reverb
    - comb all pass filter: https://github.com/calf-studio-gear/calf/blob/master/src/calf/delay.h
    - magical parameters: https://github.com/calf-studio-gear/calf/blob/master/src/audio_fx.cpp#L258
- audio 101
    - http://education.lenardaudio.com/en/
    - speed of sound, wave length, reverberation


# 2017-09-02

- fdisk, partprobe, mkswap, swapon
    - partprobe
        - it uses ioctl BLKPG with operation BLKPG_ADD_PARTITION, BLKPG_DEL_PARTITION, BLKPG_RESIZE_PARTITION.
        - follow block/ioctl.c, partition-generic.c .. (TODO)
        - usually this process is done when loading block device driver ?
    - mkswap: setup some special header to the partition (or file)
    - swapon: calls SYSCALL_DEFINE2(swapon ..) (mm/swapfile.c)
- audio visualization in polyphone
    - https://aur.archlinux.org/packages/polyphone/ (follow original tar archive link from there)
    - time domain (graphique.cpp): ui is cool (drag, zoom ui), QCustomPlot
    - frequency domain (graphiquefourier.cpp, sound.cpp):
        - only use (samplerate / 2) of samples around loop area
        - correlation (for each wave length l, calculate \\sum_{i \\in (certain range)}|x(t + i) - x(t + i + l)|)
        - FFT (tomorrow)
- midi spec
    - pitch standard, A440
    - scientific pitch notation, C4
    - note event and frequency:
        - 69 = 0x45 = A4 = 440hz
        - 60 = 0x3C = C4 = (440 * (2 ^ (- 9 / 12))) = 261.63hz
        - n = 440 * (2 ^ (n - 69) / 12) hz
    - general midi, percussion note layout
- midi note key range (2nd byte, 7 bits)

```
      decimal  |  0    12  21             60   69                      120 127
          hex  |  00   0c  15             3C   45                      78  7f
  Hz (in A440) |              33  65  131 262  440  523 1047 2097 4186
pitch notation |  C-1  C0     C1  C2  C3  C4        C5  C6   C7   C8   C9     C10
               |           A0       E2  E3     A4      A5  E6              G9
               |
               |           <---- piano 88 keys (12 * 7 + 4) ------>
               |                    <------- guitar -------->
               |                        <--- alt sax --->
```


# 2017-09-03

- Fast Fourier Transform
    - cf. complete (bi)orthogonal system, (complex) fourier series, (generalized) fourier series, discrete fourier transform
    - should study from fourier series http://mathworld.wolfram.com/FourierSeries.html
    - how does phase change appear in fourier transformed form ?
        - phase change is linear combination of same frequency, as in
          cos(x+a) = cos(x)cos(a) - sin(x)sin(a) (or e^{i(x+a)} = e^{ix} * e^{ia})
    - proof of cos(nx) and sin(nx) being complete biorthognal system (biorthognality is trivial) (TODO)
    - interpretation in real world (complex coefficient, minus frequency, sample rate, perceivable sound fequency range)
        - periodic L, upto coefficient N, sample rate r (it is L = N for any reference, but it helps understanding DFT better when explicitly having them separate)
        - X_n represents ((n / L) * r) frequency part of coefficient (seems not realy like this ..)
        - non-complex value input
            - X_n (complex fourier series's coefficients) can be represented as a_n, b_n (fourier series's coefficients)
        - how to interpret decibel ??
    - what's the "validity" of DFT ?
        - it's just a result of "mathematically correct derivation".
        - it "works practically" only because human perceives sound in frequency damain for whatever reason (or god made us in that way.)
        - does human perceives phase difference ? (eg, how about sin(x) vs ((sin(x) + cos(x)) / 2) ?)
        - shoot, actually, sqrt(2) / 2 * cos(x - pi/4) = 1 / 2 * (sin(x) + cos(x))
    - Cooley–Tukey FFT algorithm: https://en.wikipedia.org/wiki/Cooley%E2%80%93Tukey_FFT_algorithm

- lv2 ui plugin architecture
    - ex. jalv gtk host (suil), calf analyzer plugin
    - (rt -> ui)
        - (rt) suil_instance_port_event, jalv_emit_ui_events, jalv->plugin_events (control output, event output)
        - (ui) port_event callback
        - how does "port notification audio port" work (as in calf analyzer) ?
          jalv doesn't look handling it.
    - (ui -> rt)
        - (ui) changes control input port value via LV2UI_Write_Function
        - (rt) read port value as usual
    - does calf analyzer really follow this principles ?
        - calf uses instance-access extension (see methods around plugin_proxy_base (eg get_line_graph_iface ..))
        - follow gui_instantiate (lv2gui.cpp) and see how they renders stuff (see 2017-07-25-lv2.md)

- gtk
    - following calf line graph (calf_line_graph_class_init)
    - GTK_WIDGET_CLASS (vtables under this eg expose_event, button_press_event ..)
    - gtk_widget_queue_draw


# 2017-09-04

- implement fft
    - https://gitlab.com/hiogawa/fft
    - cmake: integrate git submodule, target_compile_options
    - setup googletest
    - in-place Cooley–Tukey FFT algorithm: https://en.wikipedia.org/wiki/Cooley%E2%80%93Tukey_FFT_algorithm
    - cf. [image0](./assets/2017-09-04-fft0.jpg), [image1](./assets/2017-09-04-fft1.jpg)

- what's voltage ? how could it exist in the first place ?
    - electrical potential between two points, so how does it happen ?
    - ok, it's just fundamental nature then
        - https://en.wikipedia.org/wiki/Electromagnetismthis
        - https://en.wikipedia.org/wiki/Fundamental_interaction
    - btw, how is "stuff" electrically charged (for force to be exist) ?
    - elctric charge is just a fundamental conserved property of some subatomic particles, so don't question it ?
        - https://en.wikipedia.org/wiki/Electric_charge
    - V: work per electric charge cf.
        - force (kg*m/s^2)   (as F = mass*acceralation)
        - work  (kg*m^2/s^2) (as W = F*displacement) (energy's unit is work)
        - power (watt) (kg*m^2/s^3) (as P = V*(electriccharges)/second)
    - aka electric potential, aka how much there is a "tension" to drive electric charge
    - cf. magnetic field (force): results from moving electric charges and elementary particle's spin
    - how do we have voltage (in the sense of daily life) ?
        - a whole bunch of ways to convert other energy into electric power: https://en.wikipedia.org/wiki/Power_station
        - battery drives electric charges, possibly with rechargeable characteristics, possibly using chemical reaction
          (which in tern is driven by atom or molucule level electric (aka ion) interaction)
          cf  https://en.wikipedia.org/wiki/Electric_power

- some fundamental stuff
    - fundamental (elementary) particle: a particle whose substructure is unknown by definition
    - https://en.wikipedia.org/wiki/Elementary_particle
    - atom: nucleus, electron (via electromagnetic force)
    - nucleus: proton, neutron (via nuclear force (aka residual strong force))
    - proton, neutron: some quarks (via strong force)
    - molecule: atoms (via chemical bond ie covalent bond (isn't it still eletromagnetic force?) or electromagnetic force)
    - photon

- speaker/headphone/microphone thoery and implementation
    - dynamic loudspeaker: https://en.wikipedia.org/wiki/Loudspeaker#Driver_design:_dynamic_loudspeakers
        - analog audio signal change -(a)-> magnetic force change -(b)-> sound pressure
        - (a) electromagnetic induction (Maxwell's equations) (TODO)
        - (b) is this that simple ?
        - dynamic microphone is opposite of this (condenser microphone is different)
    - condenser (capacitor) microphone: https://en.wikipedia.org/wiki/Microphone#Condenser
        - sound pressure -(a)-> change in distance betw. capacitor plates -(b)-> capacitance C change -(c)-> voltage change
    - frequency characteristics consideration ?
    - what's special in headphone compared to speaker ? not really in terms of mechanism.
    - some kind of standard which determines the loudness (decibel response) for given voltage ?
        - I mean, people don't won't to change PC sound volume when they change headphone.
        - "Sensitivity": db measured at 1meter from speaker with 1 watt power
    - http://education.lenardaudio.com/en/05_speakers.html
    - http://education.lenardaudio.com/en/10_mics.html
    - example
        - speaker: ?
        - headphone: ?
        - recorder: https://www.zoom-na.com/products/field-video-recording/field-recording/zoom-h1-handy-recorder#specs


# 2017-09-05

- 3D audio
    - https://en.wikipedia.org/wiki/Dummy_head_recording#Technical
    - https://en.wikipedia.org/wiki/Head-related_transfer_function
    - https://en.wikipedia.org/wiki/Sound_localization
    - brain compensates overall perception those small things even though we are not trying to perceive that factor "intentionally".
    - just like, without our intention, diff betw. two images from eyes are used by brain
      to make us understand the depth part of object's location.
        - https://en.wikipedia.org/wiki/Stereopsis#Geometrical_basis
        - a lot more factor than I thought https://en.wikipedia.org/wiki/Depth_perception
        - some of them must be also used for sound perception
            - eg "Familiar size": if huge-track-driving like sound's amplitude is small, human would feel that effect as distance of track
        - so, in computer graphics or AI, we need to implement such "brain" to do that part of processing.
    - other sense: visual cue, skin feeling of sound wave
    - amplitude change (panning)
    - phase/timing change
    - frequency filter based on human head and ear geometry
    - directional characteristics of original sound source matters too
    - what about in the existence of reverbation ? can it help/affect localization a lot ?
        - but, naive reverb effect implementation doesn't consider HRTF (and could break implemented HRTF effect)
    - let's see how software openal driver is implemented. and try via blender.
    - so I wanna experiment putting an earplug on one of my ear and how I can (not) recognize sound localization.
    - http://education.lenardaudio.com/en/10_mics.html
        - high frequency: amplitude difference
        - low frequency: phase difference
    - sound energy loss is affected only for high frequency factor ??
        - inverse square low ?
        - https://en.wikipedia.org/wiki/Inverse-square_law#Sound_in_a_gas

- Sound
    - https://en.wikipedia.org/wiki/Sound
    - reference sound pressure

- voltage (work per electric charge), watt (work per second) familiar examples
    - Laptop: http://psref.lenovo.com/Product/ThinkPad_13 (my pc)
        - 45-watt AC adapter (so, if we give 100V, PC will charge 45/100 ampere of electric current to chrge battery?)
        - Battery 42Wh       (power * time = work, so can this be represented as mAh ??)
    - Smartphone: https://www.asus.com/Phone/ZenFone-2-Laser-ZE500KL/specifications/ (my smartphone)
        - Battery 2400 mAh
        - USB as charger (just using V_bus pin ?)
    - USB: http://www.usb.org/developers/docs/ (Section 11.4, Power Distribution)
        - V_bus pin: 5V DC
        - unit load: 150mA (then determines W = 0.75watt)
        - separated standard for battery charging ?
    - AC plug in Japan: 100V, 50Hz (my country)
    - what is amperer (electric current I) ?
        - P = V * Q / time = V * I
        - I = V / R
        - assume V is given (eg battery's characteristics), then W is determined by I and I is determined by R or something.
        - what really comes first ? I mean, when USB standard says "device only allowed to draw 150mA", how/who impose/implement that?
        - people call it "Realization" when talking about the way to realize certain physical value (eg amperer I)
          from other value (eg voltage V) via physical laws.
        - controlling/understanding that sort of physical nature is science and engineering.
    - amperer hour: the amount of electric charges it can move (not voltage (or tension to drive electric chargs))
        - 2400mAh means if there is electric current 240mA, it will last 10h (= 2400mAh/240mA)
        - it sounds weird to use this as battery's quality since if voltage is higher,
          that will result in more work overall, but that sounds physically wrong.
    - watt hour: the amount of "work" it can do
        - 42Wh means if it is suuplying 42W, it will last 1h.
        - it sounds weird to use this as battery's quality since depending on voltage and electric current,
          it result in the different amount of electric charges battery moves overall.
          No?, voltage and electric curent anyway inter relates each other, so it's fine.
    - anyway, battery has unwritten voltage characteristics, so you can calcualate mAh and Wh from one to another ?

- boot linux on raspberry pi 3 model b
    - https://github.com/raspberrypi/firmware
    - https://www.raspberrypi.org/documentation/hardware/raspberrypi/bootmodes/
        - OTP (One time programmable memory) (why do you mention about this if it's not programmable by user ?)
        - MSD (Mass storage device (as in USB class standard))
    - https://www.raspberrypi.org/documentation/configuration/config-txt/
    - https://www.raspberrypi.org/forums/viewtopic.php?f=2&t=3042
    - http://www.denx.de/wiki/view/DULG/UBoot
    - http://elinux.org/RPi_U-Boot
    - https://archlinuxarm.org/platforms/armv8/generic
    - https://archlinuxarm.org/platforms/armv8/broadcom/raspberry-pi-3
    - let's see if there's any sketchy arch package (just looking around /var/lib/pacman/local after extracted tar archive):
        - raspberrypi-bootloader (https://archlinuxarm.org/packages/any/raspberrypi-bootloader)
            - this is just raspberrypi's upstream firmware
        - uboot-raspberrypi (https://archlinuxarm.org/packages/aarch64/uboot-raspberrypi)
            - hell yeah!, this does `cp u-boot.bin ${pkgdir}/boot/kernel8.img`.
    - So, the story is something like this:
        - GPU boots
        - GPU probes filesystem in SD card to get firmware and load it
        - GPU also read config.txt and do some hardware setup
        - GPU triggeres booting ARM CPU boots with some other firmware
        - ARM firmware loads kernel8.img (which is supposed to be linux kernel but it actually is u-boot)
        - ARM CPU executes u-boot
        - execute boot.scr
        - load kernel


# 2017-09-06, 2017-09-07

- basic audio effects
    - reverb: [image](./assets/2017-09-05-reverb.md)
    - chorus: enhance 3D-ness (is this because our brain is deceived in that way ? cf. sound localization)
    - distortion:
        - crusher (bitreduction, samplereduction): does work for classical piano, sample reduction sounds magical, but saturator works more natural sometimes
        - saturator (tap_distorgion): doesn't work for classical piano sound but this is so good for rhodes
    - filter: freaking magical biquad formulas

- random idea: osc on web project
    - https://gitlab.com/hiogawa/osc-on-web
    - http to osc proxy
    - interface in browser
    - browser ui interface drove me crazy, but I think that standard is very solid. (I'm curious how gtk, qt guys deals with this).
    - werkzeug: looks good. code is easy to follow so far (around run_simple reloading mechanism, Request/Response interface)
        - wsgi architecture is exactly same as ruby rack, so no problem with that.
    - python liblo: cython compiles python into c, that's impressive but I don't feel that's good architecture.
    - osc protocol is transport layer independent
      I prefer much thinner layering around that, like SWIG (as used in tensorflow) ?
    - so now, I don't have to use jack keyboard to play with sound effect in coffee shop.

- synthesize basic sound
    - pad
    - string
    - picky string

- human ear mechanics: https://en.wikipedia.org/wiki/Ear

- qt
    - http://doc.qt.io/qt-4.8/designer-ui-file-format.html

- sound
    - https://www.digido.com/portfolio-item/level-practices-part-2/
    - https://en.wikipedia.org/wiki/Cross-correlation
    - https://en.wikipedia.org/wiki/Precedence_effect

- cxx
    - http://en.cppreference.com/w/cpp/language/destructor
        - members and base classes destructor will be called recursively
        - eg. QXXX -> QScopedPointer<QXXPrivate>

# 2017-09-09

- lv2ui plugin with qt5
  - ui and rt communication (as far as I can tell from jalv)

- ruby fiber

- browser javascript multi process concurrency primitives
  - sharedbuffer, atomic
  - it sounds like it's not really sharing a memory

- hdr
    - ? spec

# 2017-09-10

- amazing carla's architecture
  - qt app as separate process via pipe bridging

- systemd-coredump, sysctl corepattern,

```
$ coredumpctl gdb
           PID: 2942 (jalv)
           UID: 1000 (hiogawa)
           GID: 1000 (hiogawa)
        Signal: 11 (SEGV)
     Timestamp: Sun 2017-09-10 23:18:56 JST (9min ago)
  Command Line: jalv -s http://hiogawa.net/lv2plugins/some_analyzer
    Executable: /usr/bin/jalv
 Control Group: /user.slice/user-1000.slice/session-c1.scope
          Unit: session-c1.scope
         Slice: user-1000.slice
       Session: c1
     Owner UID: 1000 (hiogawa)
       Boot ID: 98da1e0c3f624b0c86a1ec659bbaef1a
    Machine ID: c6f78d94a873436a916fea9d5065cba9
      Hostname: hiogawa-arch2
       Storage: /var/lib/systemd/coredump/core.jalv.1000.98da1e0c3f624b0c86a1ec659bbaef1a.2942.1505053136000000.lz4
       Message: Process 2942 (jalv) of user 1000 dumped core.

                Stack trace of thread 2942:
                #0  0x00007f71e5bd4120 _ZNKSt13__atomic_baseIiE4loadESt12memory_order (libQt5Core.so.5)
                #1  0x00007f71e5be446d _ZN7QStringD4Ev (libQt5Core.so.5)
                #2  0x00007f71e5bc4f89 _ZN9QHashData11free_helperEPFvPNS_4NodeEE (libQt5Core.so.5)
                #3  0x00007f71e5bdb471 _ZZN12_GLOBAL__N_123Q_QGS_globalEngineCache13innerFunctionEvEN6HolderD2Ev (libQt5Core.so.5)
                #4  0x00007f71f1cb2488 __run_exit_handlers (libc.so.6)
                #5  0x00007f71f1cb24da exit (libc.so.6)
                #6  0x00007f71f1c9bf71 __libc_start_main (libc.so.6)
                #7  0x000055fc9ba4709a n/a (jalv)

                ... other threads ...

... gdb starts here ...
GNU gdb (GDB) 8.0.1
...
Core was generated by `jalv -s http://hiogawa.net/lv2plugins/some_analyzer'.
Program terminated with signal SIGSEGV, Segmentation fault.
#0  std::__atomic_base<int>::load (__m=std::memory_order_relaxed, this=0x7f71f01ff720) at /usr/include/c++/7.1.1/bits/atomic_base.h:396
396     /usr/include/c++/7.1.1/bits/atomic_base.h: No such file or directory.
[Current thread is 1 (Thread 0x7f71f32c3b80 (LWP 2942))]
(gdb) bt
#0  0x00007f0a60be8120 in std::__atomic_base<int>::load(std::memory_order) const (__m=std::memory_order_relaxed, this=0x7f0a622bb720)
    at /usr/include/c++/7.1.1/bits/atomic_base.h:396
#1  0x00007f0a60be8120 in QAtomicOps<int>::load<int>(std::atomic<int> const&) (_q_value=...)
    at ../../include/QtCore/../../src/corelib/arch/qatomic_cxx11.h:227
#2  0x00007f0a60be8120 in QBasicAtomicInteger<int>::load() const (this=0x7f0a622bb720)
    at ../../include/QtCore/../../src/corelib/thread/qbasicatomic.h:102
#3  0x00007f0a60be8120 in QtPrivate::RefCount::deref() (this=0x7f0a622bb720) at ../../include/QtCore/../../src/corelib/tools/qrefcount.h:66
#4  0x00007f0a60bf846d in QString::~QString() (this=0x5604a2d1b500, __in_chrg=<optimized out>)
    at ../../include/QtCore/../../src/corelib/tools/qstring.h:1084
#5  0x00007f0a60bf846d in QRegExpEngineKey::~QRegExpEngineKey() (this=<optimized out>, __in_chrg=<optimized out>) at tools/qregexp.cpp:873
#6  0x00007f0a60bf846d in QHashNode<QRegExpEngineKey, QCache<QRegExpEngineKey, QRegExpEngine>::Node>::~QHashNode() (this=<optimized out>, __in_chrg=<optimized out>) at ../../include/QtCore/../../src/corelib/tools/qhash.h:149
#7  0x00007f0a60bf846d in QHash<QRegExpEngineKey, QCache<QRegExpEngineKey, QRegExpEngine>::Node>::deleteNode2(QHashData::Node*) (node=0x5604a2d1b4f0)
    at ../../include/QtCore/../../src/corelib/tools/qhash.h:536
#8  0x00007f0a60bd8f89 in QHashData::free_helper(void (*)(QHashData::Node*)) (this=0x5604a2b9e880, node_delete=0x7f0a60bf8460 <QHash<QRegExpEngineKey, QCache<QRegExpEngineKey, QRegExpEngine>::Node>::deleteNode2(QHashData::Node*)>) at tools/qhash.cpp:595
#9  0x00007f0a60bef471 in QHash<QRegExpEngineKey, QCache<QRegExpEngineKey, QRegExpEngine>::Node>::freeData(QHashData*) (this=<synthetic pointer>, x=0x5604a2b9e880) at ../../include/QtCore/../../src/corelib/tools/qhash.h:576
#10 0x00007f0a60bef471 in QHash<QRegExpEngineKey, QCache<QRegExpEngineKey, QRegExpEngine>::Node>::~QHash() (this=<synthetic pointer>, __in_chrg=<optimized out>) at ../../include/QtCore/../../src/corelib/tools/qhash.h:254
#11 0x00007f0a60bef471 in QHash<QRegExpEngineKey, QCache<QRegExpEngineKey, QRegExpEngine>::Node>::operator=(QHash<QRegExpEngineKey, QCache<QRegExpEngineKey, QRegExpEngine>::Node>&&) (other=..., this=0x7f0a611c4ef0 <(anonymous namespace)::Q_QGS_globalEngineCache::innerFunction()::holder+16>)
    at ../../include/QtCore/../../src/corelib/tools/qhash.h:260
#12 0x00007f0a60bef471 in QHash<QRegExpEngineKey, QCache<QRegExpEngineKey, QRegExpEngine>::Node>::clear() (this=0x7f0a611c4ef0 <(anonymous namespace)::Q_QGS_globalEngineCache::innerFunction()::holder+16>) at ../../include/QtCore/../../src/corelib/tools/qhash.h:582
#13 0x00007f0a60bef471 in QCache<QRegExpEngineKey, QRegExpEngine>::clear() (this=0x7f0a611c4ee0 <(anonymous namespace)::Q_QGS_globalEngineCache::innerFunction()::holder>) at tools/qcache.h:125
#14 0x00007f0a60bef471 in QCache<QRegExpEngineKey, QRegExpEngine>::~QCache() (this=0x7f0a611c4ee0 <(anonymous namespace)::Q_QGS_globalEngineCache::innerFunction()::holder>, __in_chrg=<optimized out>) at tools/qcache.h:93
#15 0x00007f0a60bef471 in (anonymous namespace)::Q_QGS_globalEngineCache::Holder::~Holder() (this=0x7f0a611c4ee0 <(anonymous namespace)::Q_QGS_globalEngineCache::innerFunction()::holder>, __in_chrg=<optimized out>) at tools/qregexp.cpp:3817
#16 0x00007f0a6cc13488 in __run_exit_handlers () at /usr/lib/libc.so.6
#17 0x00007f0a6cc134da in  () at /usr/lib/libc.so.6
#18 0x00007f0a6cbfcf71 in __libc_start_main () at /usr/lib/libc.so.6
#19 0x00005604a1e8f09a in  ()
```

- is this related ? https://stackoverflow.com/questions/21363494/need-to-change-include-path-for-clang#26841599
- looks similar http://kde-bugs-dist.kde.narkive.com/l1qXUpya/frameworks-kio-bug-373779-new-qfiledialog-integration-causes-crashes-on-program-exit
- https://stackoverflow.com/questions/8667234/why-does-my-application-crash-sometimes-with-a-sigsegv-when-it-gets-closed
- try valgrind !

- then this happens on carla
  - similar? https://bugreports.qt.io/browse/QTBUG-59721


# 2017-09-11

- chorus
  - calf's system (aka multichorus_audio_module)
    - modules_mod.cpp,h, multichorus.cpp,h, audio_fx.cpp,h
    - multichorus_audio_module
    - dsp::multichorus<.. sine_multi_lfo<float, 8> .. filter_sum<biquad_d2, biquad_d2 > ..> left, right
    - here filter_sum<biquad_d2, biquad_d2 > is only for post filter so don't mind it
    - multichorus : chorus_base : modulation_effect (inheritance)
    - procedures
      - multichorus_audio_module::params_changed =>
        - chorus_base::set_rate, set_min_delay, set_mod_depth,
        - sine_multi_lfo::set_voices, set_overlap, vphase, phase (stereo phase is setup here)
        - left.post.f1.set_bp_rbj .. (setup 2 band pass filters for left and right (only for post process))
      - multichorus_audio_module::process =>
        - left and right process completely separately
        - multichorus::process =>
          - delay.put
          - for each "voices"
            - sine_multi_lfo::get_value =>
              - calculate lfo value from voice index and vphase and overlapness and all that..
            - calculate number of samples to delay using delay, modulatin depth and lfo value
            - add up output gotten by delay.get_interp
  - parameters (lfo frequency, delay, depth, voice, overlap)
  - lfo's phase (stereo phase (betw. left and right), voice phase (betw. sine_multi_lfos))
  - looks like comb filter is modulating (which is from delay parameter)
    - depth (by ms) is about the depth of modurating "delay"
  - overlap?
  - understanding in terms of human sound localization

- https://en.wikipedia.org/wiki/Electric_guitar
  - similar to dynamic microphone (ie opposite of dynamic speaker)

- timbre (aka tone color)
  - https://en.wikipedia.org/wiki/Timbre
  - identification of "instrument" ?
  - how does machine learning tackle this now ?
  - lol

    > the psychoacoustician's multidimensional waste-basket category for everything that cannot be labeled pitch or loudness


# 2017-09-12

- calf crusher
  - sample reduction
  - bit reduction
    - number of bits
    - mode (linear or logarithm)
    - anti-aliasing

- crusher_audio_module::process =>
  - samplereduction::process (stateful. support float number of samples by m*f >= m*round(f)+1)
  - bitreduction::process (stateless)
    - waveshape (anti alias, discretization (number of bits, log, linear mode))

- gtk (glib, gobject, gdk)
  - https://www.gtk.org/documentation.php
  - https://developer.gnome.org/gobject/stable/chapter-gtype.html
  - classic
      - https://developer.gnome.org/gtk3/stable/chap-drawing-model.html
      - https://developer.gnome.org/gtk3/stable/chap-input-handling.html
  - https://developer.gnome.org/gobject/stable/howto-gobject.html
      - I usually don't mind boilerplate, but this is a bit too much ...
        I'd use it if there's a tool to generate declaration header on build time.
        (gob is closer to it, but not nice enough ?)
        (vala can be used in that way ?)
  - how gtkmm is implemented (or other any oop language binding) ?
  - this is really cool: http://helgo.net/simon/introspection-tutorial/index.xhtml
  - https://www.dwheeler.com/secure-programs/Secure-Programs-HOWTO/index.html

- openal
  - http://openal.org/documentation/openal-1.1-specification.pdf
  - http://openal-soft.org/
  - http://sound.media.mit.edu/resources/KEMAR.html
  - context: context as in GL. oh, that means context is implicit argument for the most operation ..
  - one listener per context (attributes: position, velocity, orientation (at vector, up vector))
  - multiple sources (attributes: position, velocity, direction, cone, distance attenuation model, buffer, etc..)
  - openal context, device
      - (how is "device" different from backend ? read below.)
      - static struct BackendInfo PlaybackBackend, CaptureBackend;
      - static struct BackendInfo BackendList[] (eg jack, pulse, alsa, ..)
      - alcOpenDevice(devicename) =>
        - NOTE: devicename is only for application side naming and associated configuration (not about backend)
        - DO_INITCONFIG => alc_initconfig =>
          - ReadALConfig
          - aluInitMixer
          - filter BackendList by configuration "drivers" or env var "ALSOFT_DRIVERS"
          - ALCbackendFactory::init for each factory from BackendList until init successes
            - setup PlaybackBackend, CaptureBackend
            - NOTE: alcOpenDevice's argument devicename doesn't matter at all for the way choosing backend
            - eg. ALCalsaBackendFactory_init => alsa_load => (load libasound.so)
          - InitEffectFactoryMap
          - InitEffect
        - alloc ALCdevice
        - PlaybackBackend.createBackend =>
          - NEW_OBJ(backend, ALCplaybackAlsa)
          - ALCplaybackAlsa_Construct => ALCbackend_Construct ..
        - setup openal parameters (eg channel, format (aka sample-type), freq ..)
          - use value corresponding to given "devicename" if it exists
        - Backend.open => ALCplaybackAlsa_open => snd_pcm_open
      - alcCreateContext (from device) =>
        - UpdateDeviceParams =>
          - aluInitRenderer => hrtf, ambdec
          - V0(device->Backend,start) (ie ALCplaybackAlsa_start) =>
            - althrd_create(.. ALCplaybackAlsa_mixerProc) (SEE BELOW for what this does)
        - AllocateVoices => ALvoice, ALvoiceProps (what are these ?)
        - InitContext =>
          - setup defaut parameters (or attributes) of Context and Context->Listener
        - UpdateListenerProps => context->Listener->FreeList
      - alcMakeContextCurrent => ..
      - alGenSources => al_calloc(16, sizeof(ALsource)) ..
      - alSourcei(source, ..) (eg buffer, source position, velocity)=>
        - DO_UPDATEPROPS (macro UpdateSourceProps) =>
      - alSourcePlay => alSourcePlayv =>
        - AllocateVoices ..
  - processing thread: ALCplaybackAlsa_mixerProc (THIS IS MAIN PART) =>
    - loop until self->killNow
      - snd_pcm_start,
      - snd_pcm_avail_update,
      - if avail < device->UpdateSize (aka period size), snd_pcm_wait(self->pcmHandle, 1000)
      - snd_pcm_mmap_begin
      - aluMixData =>
        - for each context in device->ContextList
          - UpdateContextSources => for each voice, CalcSourceParams =>
            - CalcAttnSourceParams =>
              - distance, orientation attenuation ..
              - doppler pitch correction ..
              - CalcPanningAndFilters =>
                - some correction based on original sound data's format (channels)
                - GetHrtfCoeffs => calculate HRIR for given elevation, azimuth angles (TODO: FOLLOW THE DETAIL)
                - CalcDirectionCoeffs(.. coeffs[MAX_AMBI_COEFFS]) => .. What's this ?? (only for effect ?)
          - for each voice in ctx->Voices
            - MixSource(voice, source, device ..) =>
              - ALfloat \*SrcData = Device->SourceData
              - LoadSamples ..
              - voice->Resampler ..
              - DoFilters ..
              - if voice->Flags&VOICE_HAS_HRTF
                - MixHrtfBlendSamples, MixHrtfSamples (aka MixHrtf) => ApplyCoeffs (convolution with hrir)
          - apply effect V(state,process)(SamplesToDo, slot->WetBuffer, state->OutBuffer)
        - MixDirectHrtf => ? (what's the reason for this ?)
        - ApplyDistanceComp(.. device->NFCtrlData)
        - WriteXX(Buffer, OutBuffer ..)
      - snd_pcm_mmap_commit
  - extensions
    - AL_EXT_SOURCE_RADIUS
    - AL_EXT_STEREO_ANGLES (alhrtf example uses this)
    - ALC_EXT_EFX (Alc/effects)
  - capture: don't talk about it, means nothing much
  - example programs (use sdl only for audio file decoding (abviously NOT for sound playback wrapper))
  - consideration for speaker setup and headphone setup ? (ambdec compensates speaker position, angle via AmbiDecoder)
  - hrtf definition files (refers docs/hrtf.txt)
    - TODO: visualize frequency response of .mhr file data (just covolving with plain sine data of each frequency should work ?)
  - when exactly non backend processing thread (or any al api call) could block by proccessing thread
    - I think al api call won't be blocked by processing because processing thread use solid atomic operation and CAS to update
      its own copy of data to mix sound.
  - size of single processing block (ie least amount number of samples where sound is rendered with parameters unchanged)
  - btw, in arch, sdl_sound is linked to sdl, but openal-examples is linked to sdl2, so those example doesn't work.
    compile with SDL would make it work, but alffplay.cpp doesn't compile for SDL.
  - https://github.com/neXyon/audaspace
    - this has utility+alpha kinds of functionality
    - use openal to give audio source location effect
    - hrtf effect (as convolution) is impemented outside of openal
    - blender's intern/audaspace is c binding version audaspace ?
  - Urho3D also has cool 3d audio setup (with SDL backend), I like this. very clean oop.
    - https://github.com/urho3d/Urho3D/tree/master/Source/Urho3D/Audio
    - openal's has much more feature but I should've read urho3d first for starter.


- https://wiki.libsdl.org/CategoryAudio
  - this is so nostalgic for me.. my first audio application was playback wav file using sdl api.
    I've looked through independent thread callback based api implementation with pulse backend.
  - lol, it wasn't that long time ago https://github.com/hi-ogawa/sound-stack


# 2017-09-13

- extract raw audio from soundfont as wav file
  - at least, polyphone does read sf2
  - or maybe I want to read through fluidsynth (fluid_synth_sfload). or linuxsampler ?
  - 1. extract raw audio data which literally living in soundfont file
  - 2. extract all available sounds from sf2 (which includes pitch compensentated keys and modulation effect etc..)
  - oh, libgig might do that already ? yes, it does. try sf2extract, sf2dump.

- soundfont (fluidsynth)
  - fluid_settings_t, fluid_synth_t, fluid_audio_driver_t, fluid_sequencer_t
  - do they internally have separate thread for event loop ? (eg, schedule_noteon, fluid_event_timer, sequencer_callback)
      - it doesn't seem that important for our usage (eg. in calf)
  - from the usage in calf (as always)
    - there's a fluid_synth_write_float(fluid_synth_t* synth, ..) interface for realtime integration
  - pitch compensation (fluid_sample_t.origpitch to fluid_voice_t.key)
  - does polyphony playback do something special ? don't think so
  - follow standard rt use flow (as in calf)
    - new_fluid_settings => ..
    - new_fluid_synth =>
      - new_fluid_defsfloader => FLUID_NEW(fluid_sfloader_t)
      - synth->channel[i] = new_fluid_channel
      - synth->voice[i] = new_fluid_voice (as many as polyphony needs)
    - fluid_synth_sfload => fluid_sfloader_load (ie fluid_defsfloader_load) =>
      - new_fluid_defsfont => FLUID_NEW(fluid_defsfont_t)
      - fluid_defsfont_load =>
        - sfload_file =>
          - FLUID_NEW (SFData)
          - load_body => chunk, process_info, process_sdta, process_pdta (cf. rifftree from libgig (linuxsampler))
        - fluid_defsfont_load_sampledata
        - (internally migrate from SFData (SFSample, ..) to fluid_defsfont_t (fluid_defpreset_t, ..) ?)
        - fluid_sample_import_sfont, fluid_defsfont_add_sample
        - fluid_defpreset_import_sfont, fluid_defsfont_add_preset
      - FLUID_NEW(fluid_sfont_t)
    - fluid_sfont_t.iteration_next (ie fluid_defsfont_sfont_iteration_next) =>
      - preset->noteon = fluid_defpreset_preset_noteon
    - fluid_synth_sfont_select, fluid_synth_bank_select, fluid_synth_program_change, fluid_synth_set_preset
    - fluid_synth_noteon => fluid_synth_noteon_LOCAL => fluid_preset_noteon (ie fluid_defpreset_preset_noteon) =>
      - fluid_defpreset_noteon =>
        - if fluid_preset_zone_inside_range, fluid_preset_zone_get_inst, fluid_inst_get_zone, fluid_inst_zone_get_sample
        - if fluid_inst_zone_inside_range
          - fluid_synth_alloc_voice =>
            - fluid_voice_init =>
              - voice->chan, voice->key, voice->vel, voice->sample = sample
              - fluid_rvoice_reset, fluid_rvoice_eventhandler_push
            - fluid_voice_add_mod ..
          - fluid_voice_add_mod if any
          - fluid_synth_start_voice => fluid_voice_start =>
            - fluid_voice_calculate_runtime_synthesis_parameters => fluid_voice_update_param
    - select_preset_in_channel => ..
    - fluid_synth_write_float =>
      - if synth->cur >= synth->curmax
        - fluid_synth_render_blocks =>
          - fluid_rvoice_eventhandler_dispatch_all => (voice to rvoice ???)
          - fluid_sample_timer_process
          - fluid_synth_add_ticks
          - fluid_rvoice_mixer_render =>
            - fluid_render_loop_singlethread =>
              - for each fluid_rvoice_mixer_t.active_voices, fluid_mixer_buffers_render_one => fluid_rvoice_write =>
                - (MAIN SYNTHESIS)
                - asdr, filter, lfo, modulator
                - voice->dsp.phase_incr = ...
                  (NOTE: this compensates the pitch key difference of original sample wave key and midi note key)
                - fluid_rvoice_dsp_interpolate_none (or linear, 4th_order, 7th_order) =>
                  - fill up dsp_buf based on original sample and phase_incr for key compensation
            - fluid_rvoice_mixer_process_fx => ..
        - fluid_rvoice_mixer_get_bufs => \*left = mixer->buffers.left_buf, right

- swig
  - llvm uses it for python binding
  - it's so fun reading example_wrap.c from the tutorial example for python
  - http://www.swig.org/Doc3.0/SWIGDocumentation.html#Introduction_nn5

- clang
  - http://clang.llvm.org
  - go through design documents
      - http://clang.llvm.org/docs/DriverInternals.html (clang binary to tool chain calls)
      - http://clang.llvm.org/docs/IntroductionToTheClangAST.html quick intro of AST (visitor sounds familiar from v8 code base)
      - http://clang.llvm.org/docs/InternalsManual.html ??
  - codegen (mapping clang AST to LLVM IR)
      - I don't find much documentation on this, but is this step such obvious ??
      - class layout, template specialization etc ..?
  - sanitizers implementation: compile time, runtime ??

- human voice
  - https://en.wikipedia.org/wiki/Human_voice
  - amplitude: vocal tract, lung airflow
  - timbre: vocal tract
  - base pitch: larynx muscle

- phonetics
  - https://en.wikipedia.org/wiki/Phonetics
  - https://en.wikipedia.org/wiki/International_Phonetic_Alphabet
  - https://en.wikipedia.org/wiki/Airstream_mechanism
  - https://en.wikipedia.org/wiki/Syllable
  - maybe fun ? https://github.com/espeak-ng/espeak-ng/


# 2017-09-14

- Physics of vocal cords
  - https://en.wikipedia.org/wiki/Vocal_folds#Function
  - https://en.wikipedia.org/wiki/Bernoulli%27s_principle
  - https://www.sciencedaily.com/releases/2016/06/160616141628.htm

- Timbre of vowels and consonants
  - by definition, timbre is the sound characteristics human can differentiates.
    so, identifing the timbre should help lanauge mastery.
  - ventriloquist: in terms of this, what's matter is only timbre. they win if
    they can mock timbre in a whatever way.

- physics of wind instrument
  - http://newt.phys.unsw.edu.au/jw/pipes.html
  - https://en.wikipedia.org/wiki/Wind_instrument#Physics_of_sound_production
  - open pipe, closed pipe
  - at the open end, moving pressure wave causes the reflection-looking wave which cancels out pressure to zero.
  - closed end is the part where pressure changes (eg reed), so no zero-out thing there.
  - flute's mouth side of end (or air reed) is not obviously "open", but that part requires to be zerod out so that's still open end.
  - then standing wave causes pipe overall to viberate
  - reed: similar to human voice cords (reed part corresponds to closed end of pipe)
  - flute: https://en.wikipedia.org/wiki/Fipple
  - brass: your lips is kinda voice cords
  - resonant frequency is the frequency of pressure wave which corresponds to
    the solution of wave equation as in string vibration.

- Timbre of string instruments difference by string instrumentsplaying method and string characteristics
  - string characteristics (piano, violin)
  - finger
  - picking
  - bow briction
  - piano (cotten coverred hammer hitting string)
  - position to hit a string
  - electric pickup characteristics (bass and guitar)
  - https://en.wikipedia.org/wiki/String_vibration
  - https://en.wikipedia.org/wiki/Wave_equation
    - wave equation to frequency (general solution is p_0(sin(wt+kx)) with w^2 = c^2*k^2)
      (for example, k = 1 / 2L (L is string or pipe length) for fundamental frequency)

- relation of opposite moving waves and standing wave  
  - frequency, wave length, amplitude
  - same actually

- "real" harmonics and their closest 12-tone notes

```
>>> A4 = 440
>>> f = lambda n: A4 * (2 ** (n / 12))
>>> harmonics = [0, 12, 12 + 7, 12 + 12, 12 + 12 + 4, 12 + 12 + 7, 12 + 12 + 10, 12 + 12 + 12]
>>> import pprint from pprint
>>> pprint.pprint([(f(0) * (i + 1), f(h)) for i, h in enumerate(harmonics)])
[(440.0, 440.0),
 (880.0, 880.0),
 (1320.0, 1318.5102276514797),
 (1760.0, 1760.0),
 (2200.0, 2217.4610478149766),
 (2640.0, 2637.02045530296),
 (3080.0, 3135.9634878539946),
 (3520.0, 3520.0)]
 ```

- python generator, iterator, comprehension
  - https://wiki.python.org/moin/Iterator
  - https://wiki.python.org/moin/Generators
  - https://docs.python.org/3.7/reference/expressions.html#displays-for-lists-sets-and-dictionaries
  - in python 3, map or filter buildin function only returns iterator so evaluation will be lazy.


# 2017-09-15

- small gui app to try out openal effect
  - https://gitlab.com/hiogawa/scratch/tree/master/try-openal  
  - https://blog.qt.io/blog/2017/01/19/should-you-be-using-qgraphicsview/
  - qt: still stick to c++ without qml. directly use QGraphicsScene. QGraphicsSceneItem is not QObject. how does qml deal with this ?
  - openal: ..

- basic audio effects (continued)
  - pulsator: lfo amplitude change, same freq but different phase for left and right
  - phaser:
      - small number of coordinated filters (aka stages) with lfo. opposite lfo phase to left and right
      - feeling like stereo wah effect
      - comparison to chorus: chorus's filter is comb (delay) (not centeralized filter),
                              chorus's lfo usually faster,
                              left and right, each have more than lfo (ie voices).
      - implementation, feedback, allpass onepole filter
      - difference of "dry amount" and "feedback"
          - "feedback" will join before all pass filter stages
          - "dry amount" is more like feedforward
          - actually these amount is something breaking the balance of allpass ness, which is essential for frequency response.
  - flanger:
      - chorus's single voice with delay filter with feedback version, and slower lfo.
      - delay feedback filter boosts up certain area of higher frequency drastically.
        so if original sound has rich harmonics (eg, violin, white noise, pad), it will sound like jet noise.
      - clear example: violin, lowest lfo frequency, use analyzer

- comb filter, intuitively
  - for example, for 1ms delay, 500Hz (= 1s / (1ms * 2)) is the lowest frequency where wave cancels out with itself.
    on the other hand, its double frequency 1000Hz is where it completely synchronize with itself.
    Generalizing it, (2n + 1) * 500 Hz will be cutoff and 2n * 500Hz will be boosted up.
    (so, 1000Hz, 2000Hz part should show 6db (= 20*log_10(_2_)) if there is frequency response graph.)
  - https://en.wikipedia.org/wiki/All-pass_filter#Digital_Implementation
  - https://ccrma.stanford.edu/~jos/pasp/Allpass_Filters.html


# 2017-09-16

- frequency response vs fourier transform
  - frequency response is about describing how linear time invariant system behaves for different frequency input.
  - fourier transform is about describing single series as the combination of frequencies.
  - good assumption in LTI assures single frequency of input doesn't affect different frequency of output.
    so, by considering both Laplace transformed version of sine input and sine output,
    H(s) will represents frequency characteristics of LTI.
  - https://en.wikipedia.org/wiki/Linear_time-invariant_theory  

- Visualize frequency response of basic filters
  - s-domain H(s) and z-domain H(z) (bilinear transformation)
  - intuitevely (z-transform as approximation of Laplace transform). [image](x).
  - TODO: frequency warp
  - first order (aka one pole) and second order (aka biquad)

- qml
  - qml, v4 http://code.qt.io/cgit/qt/qtdeclarative.git/
  - architecture http://doc.qt.io/qt-5/qml-glossary.html
  - qml type, property, method and what ? (instance, element ?)
  - inheritance ??
  - object dependency, property dependency, property binding, binding expression
    - static analysis ?
  - event system on top of signal/slot ?

- clang parsing (AST)
  - follow examples/clang-interpreter (kinda simpler version of cc1_main.cpp, ExecuteCompilerInvocation.cpp)
  - follow CompilerInstance::ExecuteAction(EmitLLVMOnlyAction)
  - pickup important class on the way
  - type checking, template specialization (are these Sema's work ?)

```
NOTE:
- "<" means inheritance
- "$" means instance

[ Data Structure ]
CompilerInstance
'-' CompilerInvocation
'-' Preprocessor
'-' ASTContext
'-' ASTConsumer
'-' Sema

EmitLLVMOnlyAction < CodeGenAction < ASTFrontendAction < FrontendAction
'-' CompilerInstance
'-' BackendConsumer < ASTConsumer
  '-' CodeGeneratorImpl < CodeGenerator < ASTConsumer
    '-' CodeGen::CodeGenModule

Parser < CodeCompletionHandler
ParsingDeclarator (RAIIObjectsForParser) < Declarator (Sema/DeclSpec)

Lexer < PreprocessorLexer


[ Procedure ]
- CompilerInstance::ExecuteAction =>
  - FrontendAction::BeginSourceFile =>
    - setCompilerInstance
    - CompilerInstance::createPreprocessor =>
      - new HeaderSearch
      - make_shared<Preprocessor>
    - CompilerInstance::createASTContext => new ASTContext
    - CreateWrappedASTConsumer => CodeGenAction::CreateASTConsumer =>
      - new BackendConsumer =>
        - clang::CreateLLVMCodeGen => new CodeGeneratorImpl => new llvm::Module ..
    - CompilerInstance::setASTConsumer
  - FrontendAction::Execute => CodeGenAction::ExecuteAction => ASTFrontendAction::ExecuteAction =>
    - CompilerInstance::createSema => new Sema($Preprocessor, $ASTContext, $ASTConsumer)
    - clang::ParseAST($Sema) =>
      - new Parser
      - Preprocessor::EnterMainSourceFile => ..
      - Parser::Initialize =>
        - Sema::Initialize => ..
        - ConsumeToken => Preprocessor::Lex => Lexer::Lex => LexTokenInternal =>
          - switch by next char and return token ..
          - (eg. macro directive (char "#")) Preprocessor::HandleDirective (PPDirectives.cpp) =>
            - LexUnexpandedToken
            - switch by directive (eg tok::pp_include) HandleIncludeDirective => ..
          - (eg. macro expansion) LexIdentifier => Preprocessor::HandleIdentifier =>
            - HandleMacroExpandedIdentifier (PPMacroExpansion.cpp) => ..
      - loop until eof
        - Parser::ParseFirstTopLevelDecl, ParseTopLevelDecl => ParseExternalDeclaration =>
          - (switch by token, eg namespace, class, function, ..)
          - (as an example follow parsing function declaration coupled with its definition)
            - ParseDeclarationOrFunctionDefinition => ParseDeclOrFunctionDefInternal =>
              - ParseDeclarationSpecifiers =>
                - (parse type as function return type)
                - ParsingDeclSpec::SetTypeSpecType (can be user defined type as identifier or buildin type)
              - ParseDeclGroup =>
                - ParsingDeclarator (< Declarator) on stack
                - ParseDeclarator => ParseDeclaratorInternal =>
                  - Parser::ParseDirectDeclarator =>
                    - (read identify token as function name)
                    - Tok.is(tok::identifier)
                    - Declarator::SetIdentifier
                    - ConsumeToken (read up to next token)
                    - ParseFunctionDeclarator =>
                      - (read parameters as function arguments prototype)
                      - ParseFunctionDeclaratorIdentifierList => ..
                - Decl *TheDecl = ParseFunctionDefinition =>
                  - Sema::ActOnStartOfFunctionDef => ..
                  - ParseFunctionStatementBody => ParseCompoundStatementBody =>
                    - loop (while Tok.isNot(tok::r_brace))
                      - ParseStatementOrDeclaration => ParseStatementOrDeclarationAfterAttributes =>
                        - (switch by token eg if, case, return ..)
                        - (for example, going for expression statement when there's no special keyword token)
                          - ParseExprStatement => ParseExpression =>
                            - ParseAssignmentExpression, ParseRHSOfBinaryExpression ..
                  - Sema::ActOnFinishFunctionBody =>
                    - (semantical check after successful parse,
                       eg, -Wmissing-prototype, I believe a lot more here but for now ..)
                - Sema::ConvertDeclToDeclGroup => ..
        - BackendConsumer::HandleTopLevelDecl =>
          - CodeGeneratorImpl::HandleTopLevelDecl =>
            - loop by DeclGroupRef, CodeGenModule::EmitTopLevelDecl =>
              - switch by Decl::getKind ..
              - (for example, Decl::Function) EmitGlobal =>
                - (seems function won't be emitted until it's used, SEE BELOW EmitDeferred)
      - BackendConsumer::HandleTranslationUnit => CodeGeneratorImpl::HandleTranslationUnit =>
        - CodeGenModule::Release =>
          - EmitDeferred =>
            - EmitGlobalDefinition => EmitGlobalFunctionDefinition =>
              - GlobalValue *GV = GetAddrOfFunction => ??
              - Fn = cast<llvm::Function>(GV)
              - setFunctionLinkage => llvm::Function::setLinkage
              - setGlobalVisibility ..
              - CodeGenFunction::GenerateCode =>
                - StartFunction =>
                  - attributes for sanitizer (eg SanitizeAddress, SanitizeThread ..)
                  - createBasicBlock("entry" ..)
                  - CGDebugInfo::EmitFunctionStart ..
                  - EmitFunctionProlog => (handle function arguments ..)
                - EmitFunctionBody => EmitCompoundStmtWithoutScope => EmitStmt =>
                  - (switch by the kind of stmt)
                  - (for example, assume function call expression) EmitIgnoredExpr => EmitAnyExpr =>
                    - EmitAggExpr => AggExprEmitter::Visit => StmtVisitor::Visit => .. =>
                      - AggExprEmitter::VisitCallExpr => CodeGenFunction::EmitCallExpr ..
                - FinishFunction => ..
          - EmitCXXGlobalInitFunc, EmitCXXThreadLocalInitFunc ..
  - FrontendAction::EndSourceFile =>
    - CodeGenAction::EndSourceFileAction =>
      - TheModule = BackendConsumer::takeModule => CodeGeneratorImpl::ReleaseModule
    - setCompilerInstance(nullptr)
```


# 2017-09-17

- clang overview (continued)
  - codegen (aka emitting llvm ir from clang AST)
  - http://llvm.org/docs/LangRef.html
  - module, linkage, visibility
  - "declare" (external symbol), "define"
  - TODO: class, template, inheritance, thread local, debug info

```
[ driver process ]
- fork exec cc1 and ld ??

[ cc1 process ]
- main (tools/driver/driver.cpp) => cc1_main =>
  - new CompilerInstance
  - clang::ExecuteCompilerInvocation =>
    - CreateFrontendAction => CreateFrontendBaseAction =>
      - switch by ProgramAction (eg -emit-obj, -emit-llvm, -ast-dump, etc ..)
    - CompilerInstance::ExecuteAction => ..
```

- llvm assembler (llvm backend) from clang cc1

```
[ Data structure ]

EmitObjAction < CodeGenAction

Target (Support/TargetRegistry.cpp)

X86TargetMachine < LLVMTargetMachine < TargetMachine

X86PassConfig < TargetPassConfig < ImmutablePass < ModulePass < Pass

PassManager < PassManagerBase
'-' PassManagerImpl

X86TTIImpl < BasicTTIImplBase<X86TTIImpl> < TargetTransformInfoImplCRTPBase < TargetTransformInfoImplBase


[ Procuder ]

(target, emission setup)
- ?? => LLVMInitializeX86TargetInfo =>
  - RegisterTarget<Triple::x86_64 ..>::RegisterTarget =>
    - TargetRegistry::RegisterTarget => (tied up TheX86_64Target into linked list)

- ?? => LLVMInitializeX86Target =>
  - getTheX86_64Target => static Target TheX86_64Target
  - RegisterTargetMachine<X86TargetMachine>::RegisterTargetMachine =>
    - TargetRegistry::RegisterTargetMachine =>
      - TheX86_64Target.TargetMachineCtorFn = &RegisterTargetMachine<X86TargetMachine>::Allocator

(pass setup)
- .. => BackendConsumer::HandleTranslationUnit =>
  - CodeGeneratorImpl::HandleTranslationUnit => .. SEE ABOVE ..
  - clang::EmitBackendOutput (BackendUtil.cpp) =>
    - EmitAssemblyHelper::EmitAssembly =>
      - CreateTargetMachine =>
        - llvm::Target *TheTarget = TargetRegistry::lookupTarget => ..
        - llvm::Target::createTargetMachine => TargetMachineCtorFn (ie RegisterTargetMachine::Allocator) =>
          - new TargetMachineImpl (ie X86TargetMachine) =>
            - computeDataLayout => ..
            - ::LLVMTargetMachine => ::TargetMachine => DL = (DataLayout as string)
      - llvm::Module::setDataLayout( TargetMachine::createDataLayout (TargetMachine's DL ) )
      - legacy::PassManager on stack (CodeGenPasses)
      - legacy::PassManager::add( X86TargetMachine::getTargetIRAnalysis (lambda X86TTIImpl) )  
      - AddEmitPasses =>
        - getCodeGenFileType =>
          - TargetMachine::CGFT_ObjectFile (if -emit-obj aka Backend_EmitObj)
        - LLVMTargetMachine::addPassesToEmitFile => addPassesToGenerateCode =>
          - X86TargetMachine::createPassConfig => new X86PassConfig
          - new MachineModuleInfo
          - legacy::PassManager::add(X86PassConfig)
          - TargetPassConfig::addISelPasses =>
            - TargetPassConfig::addISelPrepare => (if -print-isel-input, createPrintFunctionPass)
            - TargetPassConfig::addCoreISelPasses => X86PassConfig::addInstSelector =>
              - createX86ISelDag => new X86DAGToDAGISel
          - TargetPassConfig::addMachinePasses =>
            - addPass(&ExpandISelPseudosID)
            - X86PassConfig::addPreRegAlloc ..
            - createRegAllocPass => ..
      - legacy::PassManager::run => ..
```

- characteristics of basic percussive sound (timbre, frequency, envelope)
  - kick
  - snare
  - tom
  - symbal: hihat (closed, open, half-open, foot), crash, ride, splash
  - rim shot
  - brush
  - other percussions: bongo, conga, ..
  - characteristics: size, form, thinkness, what it's made of
  - electric drum integration (roland V drum)
  - samples
      - http://99sounds.org/percussion-samples/
      - http://www.loopmasters.com/genres/36-Percussion
      - https://soundpacks.com/free-sound-packs/ultimate-percussion-samples/
      - https://cymatics.fm/2016/03/04/ultimate-list-of-free-drumpercussion-samples/
      - https://www.plogue.com/phpBB3/viewtopic.php?t=7090
      - https://smmdrums.wordpress.com/category/sfz/
      - https://smmdrums.wordpress.com/category/raw-files/
  - drum sampler
      - http://www.hydrogen-music.org/hcms/
      - https://drumkv1.sourceforge.io/
      - http://openavproductions.com/fabla/
      - http://zhevny.com/specimen/

- bitcoin, blockchain
  - https://bitcoin.org/en/developer-documentation
  - https://bitcoin.org/bitcoin.pdf


# 2017-09-18

- llvm backend architecture (continued)
  - http://llvm.org/docs/CodeGenerator.html
  - http://llvm.org/docs/TableGen/BackEnds.html
  - http://llvm.org/docs/WritingAnLLVMBackend.html
  - http://llvm.org/docs/WritingAnLLVMPass.html

```
[ Data structure ]

X86TargetLowering < TargetLowering < (ir to dag ??)

X86SelectionDAGInfo < SelectionDAGTargetInfo (legal dag to x86 dag (pattern matcher))

X86RegisterInfo < X86GenRegisterInfo (X86GenRegisterInfo.inc) < TargetRegisterInfo

X86InstrInfo < X86GenInstrInfo < TargetInstrInfo

X86AsmPrinter < AsmPrinter
'-' X86MCCodeEmitter < MCCodeEmitter

X86MCInstLower (not inherited from MCInstLower)


SelectionDAGBuilder
Legalizer < MachineFunctionPass


[ Procedure ]

(TableGen use)
- X86RegisterInfo.td, X86Schedule.td, ..

(SelectionDAG phases http://llvm.org/docs/CodeGenerator.html#selectiondag-process)
- SelectionDAG construction from LLVM IR (how is it exactly DAG ?)
  - SelectionDAGBuilder
- legalize
- Select target instruction (pattern match, still SSA)
- SelectionDAG to MachineInstrs

(Register allocation)
- register spill handling (VirtRegMap)

(MC layer)
- AsmPrinter (MachineFunction to MCLabel)
  - X86AsmPrinter
- MCInstLower (MachineInstr to MCInst)
  - X86MCInstLower
- MCCodeEmitter (.o emission)
  - X86MCInstLower
```


# 2017-09-19

- my pc's memory is barely enough to link llc.
- analyzer pass is executed multiple times before all passes depends on it (eg DominatorTreeWrapperPass)
- passes before "SelectionDAGISel" (ie X86DAGToDAGISel) and passes after it is fundamentally defferent
  - one is FunctionPass and other is MachineFunctionPass
  - so, for for analyzer pass, there can be variant for both type (eg DominatorTreeWrapperPass, MachineDominatorTree)
- SelectionDAG based lowering only happens when FastISel (X86FastISel) failed to do it.
  that's why I cannot see graph from -view-xxx for my factorial function example.
  but, of cource, llvm has -fast-isel=false.
- how could SelectionDAG not be cyclic ??????
  - DAG construction happens only within single block. so there's not really cyclic ness
  - "combine" means combine nodes within single DAG.

```
(follow "llc test.ll -filtype=obj")
- main =>
  - InitializeAllTargets =>
    - InitializeAllTargetInfos => eg LLVM_TARGET(X86) --> LLVMInitializeX86TargetInfo (SEE ABOVE)
    - eg LLVM_TARGET(X86) => LLVMInitializeX86Target (SEE ABOVE)
  - InitializeAllTargetMCs, InitializeAllAsmPrinters, InitializeAllAsmParsers  
  - PassRegistry::getPassRegistry, initializeCore, initializeCodeGen .. (basic pass setup)
    - (INITIALIZE_PASS_BEGIN macros ..)
  - compileModule =>
    - parseIRFile => parseIR => .. return llvm::Module ..
    - Target *TheTarget = TargetRegistry::lookupTarget
    - Target::createTargetMachine => .. new X86TargetMachine (SEE ABOVE)
    - legacy::PassManager on stack
    - new MachineModuleInfo => initializeMachineModuleInfoPass
    - LLVMTargetMachine::addPassesToEmitFile =>
      - addPassesToGenerateCode => (SEE ABOVE)
      - addAsmPrinter =>
        - Target::createMCCodeEmitter => .. => llvm::createX86MCCodeEmitter => new X86MCCodeEmitter
        - Target::createMCAsmBackend => .. => llvm::createX86_64AsmBackend => new ELFX86_64AsmBackend
        - target::createMCObjectStreamer => llvm::createELFStreamer => new MCELFStreamer
        - (if CGFT_AssemblyFile, these will switch to createMCInstPrinter and createAsmStreamer)
        - FunctionPass *Printer = Target::createAsmPrinter => .. => new X86AsmPrinter
        - legacy::PassManager::add(Printer)
    - legacy::PassManager::run => PassManagerImpl::run =>
      - dumpPasses (for example, llc --debug-pass=Structure)
      - for each Pass (eg MPPassManager) in getContainedManager
        - MPPassManager::runOnModule => .. recursively FPPassManager::runOnModule ..


(Pass example)

X86DAGToDAGISel < SelectionDAGISel < MachineFunctionPass  < FunctionPass
'-' SelectionDAG
'-' SelectionDAGBuilder
'-' FunctionLoweringInfo


- FPPassManager::runOnModule =>
  - MachineFunctionPass::runOnFunction =>
    - MachineFunction &MF = MachineModuleInfo::getOrCreateMachineFunction($Funcion) => new MachineFunction
    - X86DAGToDAGISel::runOnMachineFunction => SelectionDAGISel::runOnMachineFunction =>
      - Function &Fn = MachineFunction::getFunction
      - X86SubTarget::getInstrInfo, ::getTargetLowering, ::getRegInfo (lookup target info)
      - SelectionDAG::init, FunctionLoweringInfo::set, SelectionDAGBuilder::init (setup based on target info)
      - SelectAllBasicBlocks =>
        - X86TargetLowering::createFastISel => new X86FastISel
        - FastISel::lowerArguments => X86FastISel::fastLowerArguments ..
        - (if FastISel failed)
          - LowerArguments => ..
          - CodeGenAndEmitDAG =>
            - SelectionDAG::Combine, LegalizeTypes, LegalizeVectors, Legalize
            - DoInstructionSelection => ??
            - CreateScheduler, Run, EmitSchedule => ??
            - SelectionDAGBuilder::UpdateSplitBlock => ??
        - for each BasicBlock in this function,
          - for each Instruction in this block, FastISel::selectInstruction => ??
          - SelectBasicBlock => ??
      - X86TargetLowering::finalizeLowering

(pass example: asm printer (emission))

X86AsmPrinter < AsmPrinter < MachineFunctionPass < FunctionPass
MCELFStreamer < MCObjectStreamer < MCStreamer

- AsmPrinter::doInitialization =>
  - X86LinuxNaClTargetObjectFile::Initialize =>
    - TargetLoweringObjectFile::Initialize =>
      - MCObjectFileInfo::InitMCObjectFileInfo => initELFMCObjectFileInfo =>
        - MCContext::getELFSection (eg ".text" ...)
    - TargetLoweringObjectFileELF::InitializeELF =>

- X86AsmPrinter::runOnMachineFunction =>
  - AsmPrinter::SetupMachineFunction => ..
  - AsmPrinter::EmitFunctionBody => ..

- AsmPrinter::doFinalization =>
  - for each Module::globals, EmitGlobalVariable =>
    - MCELFStreamer::EmitSymbolAttribute(.. MCSA_ELF_TypeObject) =>
      - MCAssembler::registerSymbol
      - MCSymbolELF::setType
      - ..
    - MCStreamer::SwitchSection => ..
    - EmitLinkage => MCELFStreamer::EmitSymbolAttribute(.. MCSA_Global)
    - EmitAlignment => MCELFStreamer::EmitValueToAlignment => MCObjectStreamer::EmitValueToAlignment =>
      - insert(new MCAlignFragment(..))
    - MCELFStreamer::EmitLabel => MCObjectStreamer::EmitLabel => MCStreamer::EmitLabel
    - EmitGlobalConstant => emitGlobalConstantImpl => MCStreamer::EmitIntValue =>
      - MCObjectStreamer::EmitBytes =>
        - MCDwarfLineEntry::Make
        - MCDataFragment::getContents::append ..
  - ..
  - MCStreamer::Finish => MCELFStreamer::FinishImpl =>
    - MCDwarfFrameEmitter::Emit => .. FrameEmitterImpl::EmitCIE ..
    - MCObjectStreamer::FinishImpl =>
      - MCDwarfLineTable::Emit
      - MCAssembler::Finish =>
        - layout($MCAsmLayout) => ..
        - ELFObjectWriter::writeObject =>
          - writeHeader (yay! finally ELF header)
          - ..
```


# 2017-09-20

- static linker
  - ldd: http://lld.llvm.org/NewLLD.html
  - static
  - difference betw. archive (ar, ranlib) and object file
      - I though archive can have information about depending shared object, but that's just because cmake makes it look like so.
        In cmake, you "add_library(xx STATIC ..)" and "target_link_libraries(xx somelib)", but cmake actually adds "-lsomelib" to
        the final executable or shared library which depends on "xx".
      - "ranlib" is "ar -s".
      - .a is just a concatination of .o + symbol table.
  - so, it doesn't seem there's so non-trivial part (except delicate perfomance requirement..) ?


- program execution
  - kernel executable loading (SYSCALL_DEFINE3(execve, ..) (fs/exec.c))
  - glibc's ld.so: https://sourceware.org/git/?p=glibc.git;a=summary
      - I don't understand the build system. seems "\_dl_start (elf/rtld)" is entry via some linker script ?
      - use kind of statically linked version of libdl.
      - LD_LIBRARY_PATH lookup ?
      - dlopen implementation (mmap? relocation?)
  - TODO: where is the program counter when efl is loaded first ?

```
$ readelf -aW /lib/ld-2.26.so
ELF Header:
  Magic:   7f 45 4c 46 02 01 01 00 00 00 00 00 00 00 00 00
  Class:                             ELF64
  Data:                              2's complement, little endian
  Version:                           1 (current)
  OS/ABI:                            UNIX - System V
  ABI Version:                       0
  Type:                              DYN (Shared object file)
  ...

$ ldd /lib/ld-2.26.so
        statically linked

$ /lib/ld-2.26.so
Usage: ld.so [OPTION]... EXECUTABLE-FILE [ARGS-FOR-PROGRAM...]
You have invoked `ld.so', the helper program for shared library executables.
This program usually lives in the file `/lib/ld.so', and special directives ..

$ readelf -lW $(type -p bash)

Elf file type is EXEC (Executable file)
Entry point 0x41b6d0
There are 9 program headers, starting at offset 64

Program Headers:
  Type           Offset   VirtAddr           PhysAddr           FileSiz  MemSiz   Flg Align
  PHDR           0x000040 0x0000000000400040 0x0000000000400040 0x0001f8 0x0001f8 R E 0x8
  INTERP         0x000238 0x0000000000400238 0x0000000000400238 0x00001c 0x00001c R   0x1
      [Requesting program interpreter: /lib64/ld-linux-x86-64.so.2]
  LOAD           0x000000 0x0000000000400000 0x0000000000400000 0x0c5b34 0x0c5b34 R E 0x200000
  ...

$ readlink -f /lib64/ld-linux-x86-64.so.2 # I'm on archlinux
/usr/lib/ld-2.26.so
```

I had some problem uderstand source around glibc/elf, so I made debug build and step execute.

```
$ # clone glibc
$ mkdir -p out/Debug/_install
$ cd out/Debug
$ ../../configure --prefix=$PWD/_install CFLAGS='-g -O1' # optimization is required to build glibc
$ make # some failed to build, but elf/ld.so was there
$ lldb ld.so
...
```

Still confused.

Here is kernel execve flow:

```
- SYSCALL_DEFINE3(execve ..) => .. => do_execveat_common =>
  - struct linux_binprm *bprm = kzalloc
  - struct file *file = do_open_execat ..
  - sched_exec => ..
  - bprm_mm_init => ..
  - prepare_binprm => ..
  - exec_binprm =>
    - search_binary_handler =>
      - for each registered struct linux_binfmt (eg elf_format, script_format)
        - linux_binfmt.load_binary
          - eg load_elf_binary =>
            - load_elf_phdrs and find INTERP
            - struct pt_regs *regs
            - unsigned long elf_entry = load_elf_interp
            - create_elf_tables(bprm ..) => bprm->p = ..
            - start_thread(regs, elf_entry (new_ip), bprm->p (new_sp)) (arch/x86/kernel/process_64.c) =>
              - start_thread_common =>
                - regs->ip = new_ip, regs->sp = new_sp ..
                - force_iret (so, next time we get back to user space, it's all brand new program ??)
          - eg load_script =>
            - parse program after "#!", bprm_change_interp, search_binary_handler recursively
    - trace_sched_process_exec
    - ptrace_event(PTRACE_EVENT_EXEC ..)
    - proc_exec_connector
```

- c++ exception implementation
  - http://llvm.org/docs/ExceptionHandling.html
  - http://en.cppreference.com/w/cpp/language/exceptions
  - scope lifetype object's destructor will be called when exception makes control to the outside of it.
  - eh_frame, personality, exception table
  - \__cxa_rethrow, \__gxx_personality_v0, \__cxa_begin_catch, \__cxa_end_catch
  - landing_pad, invoke
  - https://gitlab.com/hiogawa/scratch/blob/383187934a47c8ca9b7cb3ed434dcb0843710a37/try-clang-llvm/test5.s
      - GCC_except_table1, .Lexception0 is so freaky ..


- Urho3D
  - rendering pipeline
  - animation
  - object/scene management
  - event handling (UI, thread, ..)

```
TODO:
- [x] renderpaths, batch, queue, sourcebatch, destbatch
- [x] physics progressing frame event
- [x] model file, animation file format
- [x] animation setup, progressing frame


[ Data structure ]

Context
'-' subsystems_, eventReceivers_, factories_, ..

CharacterDemo < Sample < Application < Object
'-' Engine
  '-' ..

Node
'-* Component (components_, listeners_)
'-* Node (children_)

Scene < Node < Animatable < Serializable < Object
'-' Octree < Octant
  '-* Drawable (drawableUpdates_)
  '-* Octant
'-' PhysicsWorld
  '-' ..

Camera < Component < Animatable ..

Node ("Jack")
'-' Node ("AdjNode")
  '-' AnimatedModel < StaticModel < Drawable < Component < ..
    '-' Model ("Mutant.mdl")
      '-* VertexBuffer (OGLVertexBuffer.cpp) < GPUObject
        '-' GPUObjectHandle
      '-* IndexBuffer
      '-* Geometry (pointer to vb, ib and primitive type)
      '-' Skeleton '-* Bone
    '-* AnimationState
      '-' Animation ("Mutant_Jump1.ani")
        '-* AnimationTrack
          '-' bone
          '-* AnimationKeyFrame (tuple of time, position, rotation, scale)
      '-* AnimationStateTrack
        '-' AnimationTrack, Bone, Node
    '-* SourceBatch (number of batches == number of bones == number of geometries)
      '-' Material ("mutant_M.xml")
        (TODO: where does uv map information (coordinate) live ? that should be vertex (.mdl) isn't it ?)
        '-* TechniqueEntry '-' Technique '-* Pass (vertex/pixel shader with some parameter)
        '-* Texture (with TextureUnit (eg diffuse color, normal map, shadown map ..))
        '-* shader parameter
      '-' Geometry
        '-* VertexBuffer, IndexBuffer ..
      '-' worldTransform_ (this holds the pointer to Bone's node, so that Bone Node animation is automaticlly binded here)
    '-* Light (pixel lighting and vertex lighting)
  '-' AnimationController
    '-* AnimationControl
'-' RigidBody
'-' CollisionShape
'-' Character < LogicComponent < Component ..
  '-' Controls

Graphics (OGLGraphics.cpp)
'-' SDL_Window
'-' GraphicsImpl
  '-' SDL_GLContext

Renderer
'-* Viewport
  '-' Scene
  '-' Camera
  '-' RenderPath
    '-* RenderCommand (clear, scenepass, forwardlights)
  '-' View
    '-* Light
    '-* Drawable (NOTE: this is called geometries_ but definitely shouldn't confused with Geometry)
    '-* LightBatchQueue
      '-' Light
      '-' Texture2D (shadow map)
      '-* ShadowBatchQueue
        '-' Camera (shadow camera)
        '-' BatchQueue
    '-* BatchQueue
      '-* Batch (corresponds to single 3d geometry call)
        '-' Geometry, Material ..
    '-' RenderSurface (currentRenderTarget_) (OGLRenderSurface.cpp)
      '-' renderBuffer_


[ Procedure ]

- main (macro expanded from URHO3D_DEFINE_APPLICATION_MAIN and URHO3D_DEFINE_MAIN) =>
  - RunApplication =>
    - new Context
    - new CharacterDemo =>
      - Sample::Sample =>
        - Application::Application =>
          - new Engine =>
            - new Input => SubscribeToEvent(E_SCREENMODE ..)
            - Context::RegisterSubsystem (Engine, Input, FileSystem, Audio, Ui, etc ..)
            - RegisterSceneLibrary, RegisterPhysicsLibrary ..
      - Character::RegisterObject => ..
    - Application::Run =>
      - Sample::Setup =>
        - engineParameters_[EP_WINDOW_TITLE] = CharacterDemo::GetTypeName (ie "CharacterDemo")
      - Engine::Initialize =>
        - new Graphics (OGLGraphics.cpp) =>
          - new GraphicsImpl
          - Context::RequireSDL(SDL_INIT_VIDEO) =>
            - SDL_Init(0), SDL_InitSubSystem(SDL_INIT_VIDEO)
          - RegisterGraphicsLibrary => Object::RegisterObject (eg Animation, Shader, Camera, Light ..)
        - new Renderer => SubscribeToEvent(E_SCREENMODE ..)
        - Context::RegisterSubsystem (Graphics, Renderer)
        - Graphics::SetMode =>
          - SDL_CreateWindow
          - Restore =>
            - SDL_GL_CreateContext, SDL_GL_SetSwapInterval
            - SendEvent(E_SCREENMODE ..) --->
              - Renderer::HandleScreenMode => Initialize =>
                - CreateGeometries =>
                  - new RenderPath and Load "RenderPaths/Forward.xml"
                  - new Geometry (for dirLightGeometry_, spotLightGeometry_ ..)
                  - new TextureCube (for faceSelectCubeMap_, indirectionCubeMap_)
                - CreateInstancingBuffer => ..
                - SubscribeToEvent(E_RENDERUPDATE ..)
              - Input::HandleScreenMode => Initialize =>
                - GainFocus => SDL_ShowCursor(SDL_FALSE) ..
                - SubscribeToEvent(E_BEGINFRAME ..)
        - HiresTimer::reset
      - CharacterDemo::Start =>
        - Sample::Start =>
          - CreateConsoleAndDebugHud => Engine::CreateDebugHud => ..
          - SubscribeToEvent (E_KEYDOWN, E_KEYUP, E_SCENEUPDATE)
        - CreateScene =>
          - new Scene => subscribeToEvent(E_UPDATE ..)
          - Node::CreateComponent<Octree> => new Octree => ..
          - Node::CreateComponent<PhysicsWorld> =>
            - .. => new PhysicsWorld => bt things .. (eg new btDiscreteDynamicsWorld)
            - Node::AddComponent => Scene::ComponentAdded => PhysicsWorld::OnSceneSet =>
              - SubscribeToEvent(scene_, E_SCENESUBSYSTEMUPDATE ..)
          - new Node, Node::CreateComponent<Camera> => CreateComponent =>
            - Context::CreateObject("Camera") =>
              - lookup registered factories_
              - ObjectFactoryImpl::CreateObject => new Camera
            - Node::AddComponent($Camera) => Component::SetNode
          - Renderer::SetViewport(new Viewport)
          - Scene::CreateChild, CreateComponent<Zone>, <Light>, <StaticModel>
          - StaticModel::SetModel, SetMaterial => ..
          - CreateComponent<RigidBody>, CreateComponent<CollisionShape> (should lead to bullet counterparts)
        - CreateCharacter =>
          - CreateComponent<AnimatedModel>
          - ResourceCache::GetResource<Model> "Models/Mutant/Mutant.mdl" =>
            - Resource::Load =>
              - Model::BeginLoad =>
                - parse .mdl file (verteces, indeces, geometries, morphs)
                - Skelton::Load => list of Bone s
              - Model::EndLoad => VertexBuffer::SetData =>
                - Graphics::SetVBO (OGLGraphics.cpp) => glBindBuffer
                - glBufferData ..
          - AnimatedModel::SetModel =>
            - StaticModel::SetNumGeometries => _batches.Resize ..
            - mostly copy geometric data from Model
            - SetSkeleton =>
              - for each Bone, Node::CreateChild and Node::SetTransform(Bone::initialPosition/Rotation..)
          - AnimatedMode::SetMaterial "mutant_M.xml" =>
            - .. => Material::Load =>
              - read technique (passes), texture, parameters (TODO: when do we match technique's pass and renderpath's pass)
              - .. => Texture2D::BeginLoad ("Mutant_diffuse.jpg) => Image::BeginLoad => read DDS, KTX, PVR or leave it to stb_image
                      Texture2D::EndLoad => SetData (OGLTexture2D.cpp) => glBindTexture, glTexImage2D
              - SetTexture => ..
            - assign to SourceBatch::material
          - Node::CreateComponent<Character> =>
            - .. => new Character => SetUpdateEventMask(USE_FIXEDUPDATE)
            - Node::AddComponent => Component::SetNode => LogicComponent::OnNodeSet =>
              - Character::Start => SubscribeToEvent(.. E_NODECOLLISION ..)
        - CreateInstructions => ..
        - SubscribeToEvents => SubscribeToEvent E_UPDATE (before bullet simulation), E_POSTUPDATE (after that)
      - while !Engine::IsExiting, Engine::RunFrame =>
        - Time::BeginFrame => SendEvent(E_BEGINFRAME ..) -->
          - Input::HandleBeginFrame => Update =>
            - SDL_PollEvent (non block), HandleSDLEvent =>
              - (marshal SDL event to Urho representation)
              - SendEvent (eg E_MOUSEMOVE, E_KEYDOWN/UP, E_MOUSEBUTTONDOWN/UP ..)
        - Update =>
          - SendEvent E_UPDATE -> E_POSTUPDATE -> E_RENDERUPDATE -> E_POSTUPDATE
          - E_RENDERUPDATE -->
            - Renderer::HandleRenderUpdate => Update =>
              - LoadShaders => ..
              - QueueViewport
              - UpdateQueuedViewport =>
                - Viewport::AllocateView => new View
                - View::Define => setup View's fields (eg RenderSurface, Scene, Camera, RenderPath ..)
                - Octree::Update =>
                  - threaded UpdateDrawablesWork => Drawable::Update (eg AnimatedModel::Update) =>
                    - AnimatedModel::UpdateAnimation => ApplyAnimation =>
                      - iterate AnimationState::Apply => ApplyToModel => iterate AnimationStateTrack s and ApplyTrack =>
                        - Node::SetPosition/Rotation/Scale
                          (AnimatedModel's SourceBatche holds the pointer to Node's WorldTransform,
                           so we don't have to copy this update there)
                      - Node::MarkDirty => ..
                      - UpdateBoneBoundingBox => ..
                  - reinsert drawableUpdates_ to proper octant if it moves or something
                - View::Update =>
                  - GetDrawables =>
                    - Octree::GetDrawables($ZoneOccluderOctreeQuery) => ..
                    - CheckVisibilityWork (collect geometries_ and lights_) =>
                      - iterate drawables
                        - Drawable::UpdateBatches => update SourceBatch::distance_
                        - filter out Drawable for some case (e.g. Drawable::GetDrawDistance < GetDistance or black light)
                        - Drawable::SetMinMaxZ
                  - GetBatches =>
                    - ProcessLights => ProcessLightWork, ProcessLight =>
                      - accumulate LightQueryResult::litGeometries_ from Drawables based on light type
                      - SetupShadowCameras =>
                        - construct hypothetical "camera" to simulate ray from light to drawable (shadow caster)
                          LightQueryResult::shadowCameras_ = ..
                      - ProcessShadowCasters =>
                        - accumulate LightQueryResult::shadowCasters_ from drawables
                    - GetLightBatches =>
                      - iterate lightQueryResults_ and setup lightQueues_
                        - GetShadowMapViewport
                        - iterate shadowCasters,
                          - (skip unless material includes <pass name="shadow" ..>)
                          - AddBatchToQueue(shadowQueue.shadowBatches_ ..) =>
                            - Renderer::SetBatchShaders =>
                              - Pass::GetVertexShaders, GetPixelShaders
                              - LoadPassShaders
                            - BatchGroup::Insert  
                        - iterate litGeometries_, GetLitBatches =>
                          - iterate Drawable::GetBatches, AddBatchToQueue(lightQueue.litBaseBatches_ or litBatches_)
                        - push light itself to volumeBatches_ if we're doing deferred shading/lighting  
                    - GetBaseBatches =>
                      - (this is irrelavant forward light render path ? this matters for deferred scenepass)
                      - iterate geometries_, its batches and scenePasses_,
                        - AddBatchToQueue(pass's batch queue)
                  - Renderer::StorePreparedView
        - Render =>
          - Graphics::BeginFrame => ..
          - Renderer::Render => View::Render =>
            - UpdateGeometries =>
              - SortBatchQueueFrontToBackWork (or BatckToFront) (use Batch::renderOrder_, sortKey_, or distance_)
              - SortLightQueueWork => ..
              - SortShadowQueueWork => ..
              - Drawable::UpdateGeometry => AnimatedModel::UpdateAnimation
                 (if somehow, get dirty late (usually it should be handled Renderer::UpdateQueuedViewport))
            - AllocateScreenBuffers => (prepare Texture for some complicated render path or multiple Viewport setup ??)
            - PrepareInstancingBuffer => ..
            - ExecuteRenderPathCommands =>
              - (for example, we've got CMD_CLEAR, CMD_SCENEPASS, CMD_FORWARDLIGHTS)
              - CMD_CLEAR --> Grphics::Clear => glClear
              - CMD_SCENEPASS (skipped since !View::IsNecessary($RenderPathCommand))
              - CMD_FORWARDLIGHTS:
                - for each LightBatchQueue, RenderShadowMap =>
                  - SetRenderTargets => Graphics::SetRenderTarget => gl framebuffer setup
                  - RenderShadowMap => for splitted ShadowBatchQueue, shadowBatches_.Draw => ..
                  - litBaseBatches_.Draw (BatchQueue::Draw) =>
                    - (for sortedBatchGroups_) BatchGroup::Draw => Batch::Draw =>
                      - Prepare =>
                        - Grahiphics::SetShaders based on material =>
                          - ShaderVariation::Create => .. glCreateShader, compile
                          - new ShaderProgram, Link => .. glCreateProgram, glLinkProgram
                          - SetShaderParameter => .. glUniform
                        - global mode setup based on Pass, Material (eg BlendMode, CullMode)
                        - batch shader parameter setup (eg camera, node's worldTransform, zone's ambient color)
                        - light setup (ShaderParameter VSP_LIGHTMATRICES, PSP_LIGHTCOLOR, PSP_LIGHTDIR, PSP_LIGHTMATRICES ..)
                        - shadow map setup (..)
                        - material textures, shadow map texture
                      - Graphics::SetIndexBuffer, SetVertexBuffers, DrawInstanced =>
                        - PrepareDraw =>
                          - .. glDrawBuffer, color depth attachment (oh, I thought View::SetRenderTargets was doing this)
                          - vertex attributes setup
                        - glDrawElementsInstanced
                    - (for sortedBatches_) Batch::Draw =>
                      - Prepare => ..
                      - Geometry::Draw => Graphics::Draw => PrepareDraw, glDrawElements ..
                  - litBatches_.Draw (additive pass for additional lights (simply blend add one))
          - UI::Render => ..
          - Graphics::EndFrame => SDL_GL_SwapWindow
        - ApplyFrameLimit => ..
      - Sample::Stop => Engine::DumpResources ..


(event handlers)
- CharacterDemo::HandleUpdate =>
  - (update Character::controls_ (Controls) based on key (CTRL_XXX command) and mouse move (yaw/pitch)
    which will be used during Character::FixedUpdate
  - Character's Node::SetRotation (anyway character's rotation is not physics simulated)

- Scene::Update =>
  - SendEvent(E_SCENESUBSYSTEMUPDATE ..) -->
    - PhysicsWorld::HandleSceneSubsystemUpdate =>
      - Update => btDiscreteDynamicsWorld::stepSimulation => ..
        - (BEFORE SIMULATION)
        - Urho3D::InternalPreTickCallback => PhysicsWorld::PreStep => sendEvent(E_PHYSICSPRESTEP ..) -->
          - LogicComponent::HandlePhysicsPreStep => Character::FixedUpdate =>
            - RigidBody::ApplyImpulse (current rotation (world)) * (control direction CTRL_XXX (local))
                                      + (some force opposite to current velocity (kind of friction or air resistance)
                                         is it proportional to velocity ?)
                                      + (adding up "up force" if CTRL_JUMP)   
            - AnimationController::PlayExclusive =>
              - Play =>
                - ResourceCache::GetResource => Resource::Load => Animation::BeginLoad (parse ".ani" file)
                - AddAnimationState => AnimatedModel::AddAnimationState => AnimatedModel::AddAnimationState =>
                  - push new AnimationState(Animation) to animationStates_ => SetStartBone =>
                    - for each AnimationTrack from Animation, instantiate AnimationStateTrack with RootBone
                  - MarkAnimationOrderDirty => MarkForUpdate ..
                - animations_.push(AnimationControl binded with Animation name)
              - FadeOthers => ..
            - AnimationController::SetSpeed => ..
        - (AFTER SIMULATION)    
        - Urho3D::InternalTickCallback => PhysicsWords::PostStep => SendCollisionEvents =>
          - btCollisionDispatcher::getNumManifolds and finds collides objects
          - SendEvent(E_NODECOLLISION ..) --> Character::HandleNodeCollision =>
            - judge if onGround_ = true based on collision contact's geometric data
              (this is supposed to happen during when character sits on floor)

- AnimationController::HandleScenePostUpdate => Update =>
  - for each AnimationState binded to AnimationControl in animations_
    - AnimationState::AddTime =>
      - SetTime => AnimatedModel::MarkAnimationDirty => Drawable::MarkForUpdate =>
        - Octree::QueueUpdate => push drawable to Octree::drawableUpdates_

- CharacterDemo::HandlePostUpdate =>
  - update camera based on character's Node::GetRotation and Character::controls_.pitch
  - but for third person camera, use PhysicsWorld::RaycastSingle so not for camera to be blocked by some objects
```
